{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Setting up Environment </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "nb_actions = 5\n",
    "i_width = 227\n",
    "i_height = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arusia/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from rl.core import Env\n",
    "import numpy as np\n",
    "import sys\n",
    "import scipy.misc\n",
    "from IPython.display import clear_output\n",
    "sys.path.append('/home/arusia/fastai/airsim/AirSim/PythonClient')\n",
    "from AirSimClient import *\n",
    "class simulation(Env):\n",
    "    import time\n",
    "    reward_range = (-np.inf, np.inf)\n",
    "    observation_space = None\n",
    "    solar_coordinates = [47.64192159915037, -122.13949407490249,131.7526092529297]\n",
    "    old_dist=0\n",
    "    scale_reward_1=1\n",
    "    scale_time=1\n",
    "    state=None\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # connect to the AirSim simulator\n",
    "        self.client = MultirotorClient()\n",
    "        self.client.confirmConnection()\n",
    "        self.client.enableApiControl(True)\n",
    "        self.client.armDisarm(True)\n",
    "        self.client.takeoff()\n",
    "        self.state=self.client.getMultirotorState()\n",
    "        \n",
    "        \n",
    "    def get_image(self):\n",
    "        image_response = self.client.simGetImages([ImageRequest(0, AirSimImageType.Scene, False, False)])[0]\n",
    "        image1d = np.fromstring(image_response.image_data_uint8, dtype=np.uint8)\n",
    "        image_rgba = image1d.reshape(image_response.height, image_response.width, 4)\n",
    "        image_rgba = image_rgba[:,:,:3]\n",
    "        img=scipy.misc.imresize(image_rgba,[i_height, i_width])\n",
    "        return img\n",
    "    \n",
    "    def get_distance(self):\n",
    "        self.state=self.client.getMultirotorState()\n",
    "        alt=self.state.gps_location.altitude\n",
    "        lat=self.state.gps_location.latitude\n",
    "        lon=self.state.gps_location.longitude\n",
    "        coord=np.array([lat,lon,alt])\n",
    "        diff=coord-self.solar_coordinates\n",
    "        diff[0:2]=diff[0:2]*1e5 #Scaling factors for latitudes and longitudes\n",
    "        return np.linalg.norm(diff)\n",
    "    \n",
    "    def get_reward(self):\n",
    "        self.new_dist=self.get_distance()\n",
    "        if(self.state.collision.has_collided==True):\n",
    "            reward=-10\n",
    "            return reward\n",
    "        if(self.new_dist<1):\n",
    "            reward=10\n",
    "            return reward\n",
    "        reward = self.scale_reward_1*(-self.new_dist+self.old_dist)/self.scale_time\n",
    "        self.old_dist=self.new_dist\n",
    "        return reward\n",
    "    \n",
    "    def tonative(self,array):\n",
    "        ans=[]\n",
    "        if(np.isscalar(array)):\n",
    "            return array.item()\n",
    "        for i in range(array.size):\n",
    "            ans.insert(i,array[i].item())\n",
    "        return ans\n",
    "    \n",
    "    def step(self, action):\n",
    "        #perform action\n",
    "        \n",
    "        #find the direction to move to\n",
    "        normpara=np.linalg.norm(action[0:3])\n",
    "        direc = action[0:3]/normpara\n",
    "        \n",
    "        #find the velocity in each direction\n",
    "        velocity = direc * action[3]\n",
    "        \n",
    "        #Careful, need conversion from float32 to native float for msgpack module\n",
    "        velocity=self.tonative(velocity)\n",
    "        t=self.tonative(action[4])*self.scale_time\n",
    "        \n",
    "        self.client.moveByVelocity(velocity[0], velocity[1], velocity[2], t)\n",
    "        \n",
    "        time.sleep(t)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        #Get observations\n",
    "        self.state=self.client.getMultirotorState()\n",
    "        observation=self.get_image()\n",
    "        reward = self.get_reward()\n",
    "        done=False\n",
    "        if(self.new_dist<1):\n",
    "            done=True\n",
    "        info={}\n",
    "        \n",
    "        print(' \\n action = {} reward={}'.format(action,reward))\n",
    "        return observation,reward,done,info\n",
    "    \n",
    "    def reset(self):\n",
    "        self.client.reset()\n",
    "        self.client = MultirotorClient()\n",
    "        self.client.confirmConnection()\n",
    "        self.client.enableApiControl(True)\n",
    "        self.client.armDisarm(True)\n",
    "        self.client.takeoff()\n",
    "        self.old_dist=self.get_distance()\n",
    "        observation=self.get_image()\n",
    "        self.state=self.client.getMultirotorState()\n",
    "        return observation\n",
    "    \n",
    "    def __delete__(self):\n",
    "        self.client.reset()\n",
    "        self.client.enableApiControl(False)\n",
    "\n",
    "        \n",
    "    class a_space():\n",
    "        def sample(self,seed=None):\n",
    "            direction=-1+np.random.random(3)*2\n",
    "            speed_time=np.random.random(2)\n",
    "            return [direction[0],direction[1],direction[2],speed_time[0],speed_time[1]]\n",
    "        def contains(self,x):\n",
    "            if(max(x[0:3])>1 or min(x[0:3])<-1):\n",
    "                return False\n",
    "            \n",
    "            if(max(x[0:3])>1 or min(x[0:3])<0):\n",
    "                return False\n",
    "            return True\n",
    "        \n",
    "    action_space = a_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Getting vanilla SqueezeNet to be used as the driver </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras_squeezenet import SqueezeNet\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Dense,Flatten,Input,Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "def get_actor():\n",
    "    model = SqueezeNet()\n",
    "    hid=Dense(512,activation='relu')(model.layers[-2].output)\n",
    "    x=Dense(1, activation='tanh')(hid)\n",
    "    y=Dense(1, activation='tanh')(hid)\n",
    "    z=Dense(1, activation='tanh')(hid)\n",
    "    v=Dense(1, activation='sigmoid')(hid)\n",
    "    t=Dense(1, activation='sigmoid')(hid)\n",
    "    out=Concatenate()([x,y,z,v,t])\n",
    "    Driver = Model(inputs=model.layers[0].output, outputs=out)\n",
    "    return Driver\n",
    "\n",
    "def get_critic():\n",
    "    model = SqueezeNet()\n",
    "    \n",
    "    features=model.layers[-2].output\n",
    "    action=Input(shape=(nb_actions,),name=\"input_action\")\n",
    "    conc=Concatenate()([features,action])\n",
    "    hid=Dense(512,activation='relu')(conc)\n",
    "    output_layer=Dense(1, activation='sigmoid')(hid)\n",
    "    Driver = Model(inputs=[model.layers[0].output,action], outputs=output_layer)\n",
    "    return Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Writing a reinforcement learning routine</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "class random_proc(OrnsteinUhlenbeckProcess):\n",
    "    def sample(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n",
    "        x[self.size-1]=abs(x[self.size-1])\n",
    "        self.x_prev = x\n",
    "        self.n_steps += 1\n",
    "        return x\n",
    "\n",
    "from rl.core import Processor\n",
    "class Sim_processor(Processor):\n",
    "    def process_step(self, observation, reward, done, info):\n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def process_action(self, action):\n",
    "        action[0:3]=np.clip(action[0:3],-1.0,1.0)\n",
    "        action[3:5]=np.clip(action[3:5],0.0,1.0)\n",
    "        return action\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        \"\"\"The metrics of the processor, which will be reported during training.\n",
    "\n",
    "        # Returns\n",
    "            List of `lambda y_true, y_pred: metric` functions.\n",
    "        \"\"\"\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def metrics_names(self):\n",
    "        \"\"\"The human-readable names of the agent's metrics. Must return as many names as there\n",
    "        are metrics (see also `compile`).\n",
    "        \"\"\"\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " action = [ 0.59640276 -0.15872204  0.41836798  0.9087057   0.05655092] reward=-10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DDPGAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "\n",
    "\n",
    "ENV_NAME='airsim'\n",
    "env=simulation()\n",
    "# Get actor and critic\n",
    "actor=get_actor()\n",
    "critic=get_critic()\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "\n",
    "random_process = None #random_proc(size=nb_actions, theta=.15, mu=0., sigma=.3)\n",
    "processor_instance=Sim_processor()\n",
    "agent = DDPGAgent(nb_actions=nb_actions, actor=actor, critic=critic, critic_action_input=critic.input[1],\n",
    "                  memory=memory, nb_steps_warmup_critic=100, nb_steps_warmup_actor=100,batch_size=2,\n",
    "                  random_process=random_process, gamma=.97, target_model_update=0.5,processor=processor_instance)\n",
    "agent.compile(Adam(lr=.01), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "#agent.load_weights('ddpg_{}_weights.h5f'.format(ENV_NAME))\n",
    "agent.fit(env, nb_steps=50000, visualize=False, verbose=1, nb_max_episode_steps=200)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "agent.save_weights('ddpg_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "env.__delete__()\n",
    "agent.test(env, nb_episodes=5, visualize=False, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(agent.processor.metrics_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences=agent.memory.sample(agent.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.memory import zeroed_observation\n",
    "x=[agent.memory.observations[0]]\n",
    "x.insert(0,zeroed_observation(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences[31].state1[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.__delete__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# After training is done, we save the final weights.\n",
    "agent.save_weights('ddpg_{}_weights.h5f'.format(ENV_NAME), overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
