{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Setting up Environment </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "nb_actions = 5\n",
    "i_width = 227\n",
    "i_height = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arusia/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from rl.core import Env\n",
    "import numpy as np\n",
    "import sys\n",
    "import scipy.misc\n",
    "sys.path.append('/home/arusia/fastai/airsim/AirSim/PythonClient')\n",
    "from AirSimClient import *\n",
    "class simulation(Env):\n",
    "    import time\n",
    "    reward_range = (-np.inf, np.inf)\n",
    "    observation_space = None\n",
    "    solar_coordinates = [3800,180,100]\n",
    "    old_dist=0\n",
    "    scale_reward_1=0.3\n",
    "    state=None\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        # connect to the AirSim simulator\n",
    "        self.client = MultirotorClient()\n",
    "        self.client.confirmConnection()\n",
    "        self.client.enableApiControl(True)\n",
    "        self.client.armDisarm(True)\n",
    "        self.client.takeoff()\n",
    "        self.state=self.client.getMultirotorState()\n",
    "        \n",
    "        \n",
    "    def get_image(self):\n",
    "        image_response = self.client.simGetImages([ImageRequest(0, AirSimImageType.Scene, False, False)])[0]\n",
    "        image1d = np.fromstring(image_response.image_data_uint8, dtype=np.uint8)\n",
    "        image_rgba = image1d.reshape(image_response.height, image_response.width, 4)\n",
    "        image_rgba = image_rgba[:,:,:3]\n",
    "        img=scipy.misc.imresize(image_rgba,[i_height, i_width])\n",
    "        return img\n",
    "    \n",
    "    def get_distance(self):\n",
    "        alt=self.state.gps_location.altitude\n",
    "        lat=self.state.gps_location.latitude\n",
    "        lon=self.state.gps_location.longitude\n",
    "        coord=np.array([lat,lon,alt])\n",
    "        return np.sqrt(np.linalg.norm(coord-self.solar_coordinates))\n",
    "    \n",
    "    def get_reward(self):\n",
    "        self.new_dist=self.get_distance()\n",
    "        if(self.state.collision.has_collided==True):\n",
    "            reward=-1\n",
    "            return reward\n",
    "        if(self.new_dist<10):\n",
    "            reward=1\n",
    "            return reward\n",
    "        reward = self.scale_reward_1*(-self.new_dist+self.old_dist)\n",
    "        self.old_dist=self.new_dist\n",
    "        return reward\n",
    "    \n",
    "    def tonative(self,array):\n",
    "        ans=[]\n",
    "        if(np.isscalar(array)):\n",
    "            return array.item()\n",
    "        for i in range(array.size):\n",
    "            ans.insert(i,array[i].item())\n",
    "        return ans\n",
    "    def step(self, action):\n",
    "        #perform action\n",
    "        \n",
    "        #find the direction to move to\n",
    "        normpara=np.linalg.norm(action[0:3])\n",
    "        direc = action[0:3]/normpara\n",
    "        \n",
    "        #find the velocity in each direction\n",
    "        velocity = direc * action[3]\n",
    "        \n",
    "        #Careful, need conversion from float32 to native float for msgpack module\n",
    "        velocity=self.tonative(velocity)\n",
    "        t=self.tonative(action[4])\n",
    "        \n",
    "        self.client.moveByVelocity(velocity[0], velocity[1], velocity[2], t)\n",
    "        time.sleep(action[4])\n",
    "        \n",
    "        #Get observations\n",
    "        self.state=self.client.getMultirotorState()\n",
    "        observation=self.get_image()\n",
    "        reward = self.get_reward()\n",
    "        done=False\n",
    "        if(self.new_dist<10):\n",
    "            done=True\n",
    "        info={}\n",
    "        return observation,reward,done,info\n",
    "    \n",
    "    def reset(self):\n",
    "        self.client.reset()\n",
    "        self.client = MultirotorClient()\n",
    "        self.client.confirmConnection()\n",
    "        self.client.enableApiControl(True)\n",
    "        self.client.armDisarm(True)\n",
    "        self.client.takeoff()\n",
    "        self.old_dist=self.get_distance()\n",
    "        observation=self.get_image()\n",
    "        self.state=self.client.getMultirotorState()\n",
    "        return observation\n",
    "    \n",
    "    def delete(self):\n",
    "        self.client.reset()\n",
    "        self.client.enableApiControl(False)\n",
    "\n",
    "        \n",
    "    def a_space(self):\n",
    "        def sample(self,seed=None):\n",
    "            direction=-1+np.random.random(1)*2\n",
    "            speed_time=np.random.random(1)\n",
    "            return [direction[0],direction[1],direction[2],speed_time[0],speed_time[1]]\n",
    "        def contains(self,x):\n",
    "            if(max(x[0:3])>1 or min(x[0:3])<-1):\n",
    "                return False\n",
    "            \n",
    "            if(max(x[0:3])>1 or min(x[0:3])<0):\n",
    "                return False\n",
    "            return True\n",
    "        \n",
    "    action_space = a_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Getting vanilla SqueezeNet to be used as the driver </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras_squeezenet import SqueezeNet\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Dense,Flatten,Input,Concatenate\n",
    "from keras.models import Model\n",
    "\n",
    "def get_actor():\n",
    "    model = SqueezeNet()\n",
    "    hid=Dense(512,activation='relu')(model.layers[-2].output)\n",
    "    x=Dense(1, activation='tanh')(hid)\n",
    "    y=Dense(1, activation='tanh')(hid)\n",
    "    z=Dense(1, activation='tanh')(hid)\n",
    "    v=Dense(1, activation='sigmoid')(hid)\n",
    "    t=Dense(1, activation='sigmoid')(hid)\n",
    "    out=Concatenate()([x,y,z,v,t])\n",
    "    Driver = Model(inputs=model.layers[0].output, outputs=out)\n",
    "    return Driver\n",
    "\n",
    "def get_critic():\n",
    "    model = SqueezeNet()\n",
    "    \n",
    "    features=model.layers[-2].output\n",
    "    action=Input(shape=(nb_actions,),name=\"input_action\")\n",
    "    conc=Concatenate()([features,action])\n",
    "    hid=Dense(512,activation='relu')(conc)\n",
    "    output_layer=Dense(1, activation='sigmoid')(hid)\n",
    "    Driver = Model(inputs=[model.layers[0].output,action], outputs=output_layer)\n",
    "    return Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Writing a reinforcement learning routine</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "class random_proc(OrnsteinUhlenbeckProcess):\n",
    "    def sample(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n",
    "        x[self.size-1]=abs(x[self.size-1])\n",
    "        self.x_prev = x\n",
    "        self.n_steps += 1\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for connection: \n",
      "Training for 50000 steps ...\n",
      "Waiting for connection: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arusia/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:29: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "/home/arusia/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:32: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interval 1 (0 steps performed)\n",
      "  123/10000 [..............................] - ETA: 4:14:41 - reward: -0.5203done, took 205.937 seconds\n",
      "Testing for 5 episodes ...\n",
      "Waiting for connection: \n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-7305204f8e2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# Finally, evaluate our algorithm for 5 episodes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvisualize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_max_episode_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/arusia/fastai/airsim/rl/core.pyc\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, env, nb_episodes, action_repetition, callbacks, visualize, nb_max_episode_steps, nb_max_start_steps, start_step_policy, verbose)\u001b[0m\n\u001b[1;32m    316\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                         \u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_action_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mreward\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arusia/fastai/airsim/rl/callbacks.pyc\u001b[0m in \u001b[0;36mon_action_end\u001b[0;34m(self, action, logs)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'on_action_end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_action_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arusia/fastai/airsim/rl/callbacks.pyc\u001b[0m in \u001b[0;36mon_action_end\u001b[0;34m(self, action, logs)\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mVisualizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCallback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_action_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'human'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/arusia/fastai/airsim/rl/core.pyc\u001b[0m in \u001b[0;36mrender\u001b[0;34m(self, mode, close)\u001b[0m\n\u001b[1;32m    574\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mClose\u001b[0m \u001b[0mall\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mrenderings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         \"\"\"\n\u001b[0;32m--> 576\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents import DDPGAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "\n",
    "\n",
    "ENV_NAME='airsim'\n",
    "env=simulation()\n",
    "# Get actor and critic\n",
    "actor=get_actor()\n",
    "critic=get_critic()\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "\n",
    "random_process = random_proc(size=nb_actions, theta=.15, mu=0., sigma=.3)\n",
    "\n",
    "agent = DDPGAgent(nb_actions=nb_actions, actor=actor, critic=critic, critic_action_input=critic.input[1],\n",
    "                  memory=memory, nb_steps_warmup_critic=100, nb_steps_warmup_actor=100,\n",
    "                  random_process=random_process, gamma=.97, target_model_update=1e-3)\n",
    "agent.compile(Adam(lr=.001, clipnorm=1.), metrics=['mae'])\n",
    "\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "agent.fit(env, nb_steps=50000, visualize=False, verbose=1, nb_max_episode_steps=200)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "agent.save_weights('ddpg_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "agent.test(env, nb_episodes=5, visualize=False, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences=agent.memory.sample(agent.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.memory import zeroed_observation\n",
    "x=[agent.memory.observations[0]]\n",
    "x.insert(0,zeroed_observation(x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences[31].state1[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
