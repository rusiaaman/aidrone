{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Setting up Environment </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "nb_actions = 5\n",
    "i_width = 227\n",
    "i_height = 227"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arusia/miniconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for connection: \n"
     ]
    }
   ],
   "source": [
    "from rl.core import Env\n",
    "import numpy as np\n",
    "import sys\n",
    "import scipy.misc\n",
    "from IPython.display import clear_output\n",
    "sys.path.append('/home/arusia/fastai/airsim/AirSim/PythonClient')\n",
    "from AirSimClient import *\n",
    "\n",
    "# connect to the AirSim simulator\n",
    "client = MultirotorClient()\n",
    "client.confirmConnection()\n",
    "client.enableApiControl(True)\n",
    "client.armDisarm(True)\n",
    "\n",
    "\n",
    "class simulation(Env):\n",
    "    import time\n",
    "    reward_range = (-np.inf, np.inf)\n",
    "    observation_space = None\n",
    "    solar_coordinates = [47.64192159915037, -122.13949407490249,131.7526092529297]\n",
    "    old_dist=0\n",
    "    scale_reward_1=1\n",
    "    scale_time=1\n",
    "    state=None\n",
    "    \n",
    "    def __init__(self):\n",
    "        client.enableApiControl(True)\n",
    "        client.takeoff()\n",
    "        self.state=client.getMultirotorState()\n",
    "        \n",
    "        \n",
    "    def get_image(self):\n",
    "        image_response = client.simGetImages([ImageRequest(0, AirSimImageType.Scene, False, False)])[0]\n",
    "        image1d = np.fromstring(image_response.image_data_uint8, dtype=np.uint8)\n",
    "        image_rgba = image1d.reshape(image_response.height, image_response.width, 4)\n",
    "        image_rgba = image_rgba[:,:,:3]\n",
    "        img=scipy.misc.imresize(image_rgba,[i_height, i_width])\n",
    "        return img\n",
    "    \n",
    "    def get_distance(self):\n",
    "        self.state=client.getMultirotorState()\n",
    "        alt=self.state.gps_location.altitude\n",
    "        lat=self.state.gps_location.latitude\n",
    "        lon=self.state.gps_location.longitude\n",
    "        coord=np.array([lat,lon,alt])\n",
    "        diff=coord-self.solar_coordinates\n",
    "        diff[0:2]=diff[0:2]*1e5 #Scaling factors for latitudes and longitudes\n",
    "        return np.linalg.norm(diff)\n",
    "    \n",
    "    def get_reward(self):\n",
    "        self.new_dist=self.get_distance()\n",
    "        if(self.state.collision.has_collided):\n",
    "            reward=-1000\n",
    "            return reward\n",
    "        if(self.new_dist<1):\n",
    "            reward=1000\n",
    "            return reward\n",
    "        reward = self.scale_reward_1*(-self.new_dist+self.old_dist)/self.scale_time\n",
    "        self.old_dist=self.new_dist\n",
    "        reward=np.around(reward,decimals=1)\n",
    "        return reward\n",
    "    \n",
    "    def tonative(self,array):\n",
    "        ans=[]\n",
    "        if(np.isscalar(array)):\n",
    "            return array.item()\n",
    "        for i in range(array.size):\n",
    "            ans.insert(i,array[i].item())\n",
    "        return ans\n",
    "    \n",
    "    def step(self, action):\n",
    "        #perform action\n",
    "        \n",
    "        #find the direction to move to\n",
    "        normpara=np.linalg.norm(action[0:3])\n",
    "        direc = action[0:3]/normpara\n",
    "        \n",
    "        #find the velocity in each direction\n",
    "        velocity = direc * action[3]\n",
    "        \n",
    "        #Careful, need conversion from float32 to native float for msgpack module\n",
    "        velocity=self.tonative(velocity)\n",
    "        t=self.tonative(action[4])*self.scale_time\n",
    "        \n",
    "        client.moveByVelocity(velocity[0], velocity[1], velocity[2], t)\n",
    "        \n",
    "        time.sleep(t)\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        #Get observations\n",
    "        self.state=client.getMultirotorState()\n",
    "        observation=self.get_image()\n",
    "        reward = self.get_reward()\n",
    "        done=False\n",
    "        if(self.new_dist<1 or self.state.collision.has_collided):\n",
    "            done=True\n",
    "        info={}\n",
    "        \n",
    "        print(' \\n velocity = {},{},{}, time={} reward={}'.format(velocity[0], velocity[1], velocity[2], t,reward))\n",
    "        return observation,reward,done,info\n",
    "    \n",
    "    def reset(self):\n",
    "        client.reset()\n",
    "        client.enableApiControl(True)\n",
    "        client.takeoff()\n",
    "        self.old_dist=self.get_distance()\n",
    "        observation=self.get_image()\n",
    "        self.state=client.getMultirotorState()\n",
    "        return observation\n",
    "    \n",
    "    def __del__(self):\n",
    "        client.reset()\n",
    "        client.enableApiControl(True)\n",
    "\n",
    "        \n",
    "    class a_space():\n",
    "        def sample(self,seed=None):\n",
    "            direction=-1+np.random.random(3)*2\n",
    "            speed_time=np.random.random(2)\n",
    "            return [direction[0],direction[1],direction[2],speed_time[0],speed_time[1]]\n",
    "        def contains(self,x):\n",
    "            if(max(x[0:3])>1 or min(x[0:3])<-1):\n",
    "                return False\n",
    "            \n",
    "            if(max(x[0:3])>1 or min(x[0:3])<0):\n",
    "                return False\n",
    "            return True\n",
    "        \n",
    "    action_space = a_space()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Getting vanilla SqueezeNet to be used as the driver </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras_squeezenet import SqueezeNet\n",
    "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import layers\n",
    "from keras.layers import Dense,Flatten,Input,Concatenate,BatchNormalization,Dropout,Conv2D,MaxPooling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "K.set_learning_phase(0) #set learning phase\n",
    "def get_actor2():\n",
    "    input1=Input(shape=(227,227,3,),name=\"observation\")\n",
    "    Con=Conv2D(1,kernel_size=3,strides=2,activation='relu')(input1)\n",
    "    Con=MaxPooling2D(pool_size=(4,4))(Con)\n",
    "    hid=Flatten()(Con)\n",
    "    hid=Dense(512,activation='relu')(hid)\n",
    "    hid=Dropout(0.4)(hid)\n",
    "    \n",
    "    x=Dense(1, activation='tanh')(hid)\n",
    "    y=Dense(1, activation='tanh')(hid)\n",
    "    z=Dense(1, activation='tanh')(hid)\n",
    "    v=Dense(1, activation='sigmoid')(hid)\n",
    "    t=Dense(1, activation='sigmoid')(hid)\n",
    "    out=Concatenate()([x,y,z,v,t])\n",
    "    Driver=Model(inputs=input1,outputs=out)\n",
    "    return Driver\n",
    "\n",
    "def get_critic2():\n",
    "    input1=Input(shape=(227,227,3,),name=\"observation\")\n",
    "    Con=Conv2D(1,kernel_size=3,strides=2,activation='relu')(input1)\n",
    "    Con=MaxPooling2D(pool_size=(4,4))(Con)\n",
    "    features=Flatten()(Con)\n",
    "    action=Input(shape=(nb_actions,),name=\"input_action\")\n",
    "    \n",
    "    conc=Concatenate()([features,(action)])\n",
    "    hid=Dense(512,activation='relu')(conc)\n",
    "    hid=Dropout(0.4)(hid)\n",
    "    output_layer=Dense(1, activation='sigmoid')(hid)\n",
    "    Driver = Model(inputs=[input1,action], outputs=output_layer)\n",
    "    return Driver\n",
    "    \n",
    "def get_actor():\n",
    "    model = SqueezeNet()\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=False\n",
    "    hid=(model.layers[-2].output)\n",
    "    hid=Dense(512,activation='relu')(hid)\n",
    "    hid=Dropout(0.4)(hid)\n",
    "    x=Dense(1, activation='tanh')(hid)\n",
    "    y=Dense(1, activation='tanh')(hid)\n",
    "    z=Dense(1, activation='tanh')(hid)\n",
    "    v=Dense(1, activation='sigmoid')(hid)\n",
    "    t=Dense(1, activation='sigmoid')(hid)\n",
    "    out=Concatenate()([x,y,z,v,t])\n",
    "    Driver = Model(inputs=model.layers[0].output, outputs=out)\n",
    "    return Driver\n",
    "\n",
    "def get_critic():\n",
    "    model = SqueezeNet()\n",
    "    for layer in model.layers:\n",
    "        layer.trainable=False\n",
    "    features=model.layers[-2].output\n",
    "    action=Input(shape=(nb_actions,),name=\"input_action\")\n",
    "    batchaction=(action)\n",
    "    conc=Concatenate()([features,batchaction])\n",
    "    hid=Dense(512,activation='relu')(conc)\n",
    "    hid=Dropout(0.4)(hid)\n",
    "    output_layer=Dense(1, activation='sigmoid')(hid)\n",
    "    Driver = Model(inputs=[model.layers[0].output,action], outputs=output_layer)\n",
    "    return Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Writing a reinforcement learning routine</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "\n",
    "def get_callbacks(filepath, patience=2):\n",
    "    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n",
    "    msave = ModelCheckpoint(filepath, save_best_only=True)\n",
    "    return [es, msave]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "class random_proc2(OrnsteinUhlenbeckProcess):\n",
    "    def sample(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n",
    "        x[self.size-1]=abs(x[self.size-1])\n",
    "        self.x_prev = x\n",
    "        self.n_steps += 1\n",
    "        return x\n",
    "    \n",
    "    def epsilon(self,x,e):\n",
    "        if(np.random.random()<=e):\n",
    "            direction=-1+np.random.random(3)*2\n",
    "            speed_time=np.random.random(2)\n",
    "            return np.array([direction[0],direction[1],direction[2],speed_time[0],speed_time[1]])\n",
    "        return x\n",
    "class random_proc(OrnsteinUhlenbeckProcess):    \n",
    "    def sample(self):\n",
    "        x = self.x_prev + self.theta * (self.mu - self.x_prev) * self.dt + self.current_sigma * np.sqrt(self.dt) * np.random.normal(size=self.size)\n",
    "        self.x_prev = x\n",
    "        self.n_steps += 1\n",
    "        x=x+self.translate\n",
    "        x[self.size-2:self.size]=abs(x[self.size-2:self.size])\n",
    "        print x\n",
    "        return x\n",
    "    \n",
    "from rl.core import Processor\n",
    "class Sim_processor(Processor):\n",
    "    def process_step(self, observation, reward, done, info):\n",
    "        return observation, reward, done, info\n",
    "    \n",
    "    def process_action(self, action):\n",
    "        action[0:3]=np.clip(action[0:3],-1.0,1.0)\n",
    "        action[3:5]=np.clip(action[3:5],0.0,1.0)\n",
    "        return action\n",
    "    \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        \"\"\"The metrics of the processor, which will be reported during training.\n",
    "\n",
    "        # Returns\n",
    "            List of `lambda y_true, y_pred: metric` functions.\n",
    "        \"\"\"\n",
    "        return []\n",
    "\n",
    "    @property\n",
    "    def metrics_names(self):\n",
    "        \"\"\"The human-readable names of the agent's metrics. Must return as many names as there\n",
    "        are metrics (see also `compile`).\n",
    "        \"\"\"\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updating exploring actor with sigma = 1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Flatten, Input, Concatenate\n",
    "from keras.optimizers import Adam,Nadam\n",
    "\n",
    "from rl.agents import DDPGAgent\n",
    "from rl.memory import SequentialMemory\n",
    "from rl.random import OrnsteinUhlenbeckProcess\n",
    "\n",
    "\n",
    "ENV_NAME='airsim'\n",
    "env=simulation()\n",
    "# Get actor and critic\n",
    "actor=get_actor()\n",
    "critic=get_critic()\n",
    "\n",
    "# Finally, we configure and compile our agent. You can use every built-in Keras optimizer and\n",
    "# even the metrics!\n",
    "memory = SequentialMemory(limit=100000, window_length=1)\n",
    "\n",
    "random_process = random_proc(size=nb_actions, theta=0.15, mu=0., sigma=1.0)\n",
    "processor_instance=Sim_processor()\n",
    "agent = DDPGAgent(nb_actions=nb_actions, actor=actor, critic=critic, critic_action_input=critic.input[1],\n",
    "                  memory=memory, nb_steps_warmup_critic=100, nb_steps_warmup_actor=100,batch_size=8,\n",
    "                  random_process=random_process, gamma=.99, target_model_update=3,processor=processor_instance,\n",
    "                  _am_epsilon=0.0,parameter_random=True)\n",
    "agent.compile(Nadam(lr=.001), metrics=['mae'])\n",
    "\n",
    "#agent.load_weights('ddpg_airsim_weights.h5f')\n",
    "# Okay, now it's time to learn something! We visualize the training here for show, but this\n",
    "# slows down training quite a lot. You can always safely abort the training prematurely using\n",
    "# Ctrl + C.\n",
    "#agent.load_weights('ddpg_{}_weights.h5f'.format(ENV_NAME))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arusia/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:34: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead\n",
      "/home/arusia/miniconda2/lib/python2.7/site-packages/ipykernel_launcher.py:37: DeprecationWarning: `imresize` is deprecated!\n",
      "`imresize` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``skimage.transform.resize`` instead.\n"
     ]
    }
   ],
   "source": [
    "img=env.get_image()\n",
    "img=np.expand_dims(img, axis=0)\n",
    "action=actor.predict(img)\n",
    "random_process.translate=-1*action[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " velocity = -0.577350258827,0.577350258827,-0.577350258827, time=1.0 reward=0.3\n",
      "updating exploring actor with sigma = 0.262144\n",
      "  372/10000 [>.............................] - ETA: 2:26:39 - reward: -16.1414"
     ]
    }
   ],
   "source": [
    "agent.fit(env, nb_steps=50000, visualize=False, verbose=1, nb_max_episode_steps=200)\n",
    "\n",
    "# After training is done, we save the final weights.\n",
    "agent.save_weights('ddpg_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n",
    "\n",
    "# Finally, evaluate our algorithm for 5 episodes.\n",
    "env.__del__()\n",
    "agent.test(env, nb_episodes=5, visualize=False, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.batch_size=16\n",
    "agent.fit(env, nb_steps=50000, visualize=False, verbose=1, nb_max_episode_steps=200)\n",
    "# After training is done, we save the final weights.\n",
    "agent.save_weights('ddpg_{}_weights.h5f'.format(ENV_NAME), overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# After training is done, we save the final weights.\n",
    "\n",
    "agent.load_weights('ddpg_{}_weights.h5f'.format(ENV_NAME))\n",
    "\n",
    "agent.test(env, nb_episodes=5, visualize=False, nb_max_episode_steps=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "env.__del__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in actor.layers:\n",
    "    if(layer.trainable):\n",
    "        layer_weights=layer.get_weights()\n",
    "        if(layer_weights==[]):\n",
    "            continue\n",
    "        layer_weights[0]=layer_weights[0]+np.random.normal(0,1,layer_weights[0].shape)\n",
    "        layer_weights[1]=layer_weights[1]+np.random.normal(0,1,layer_weights[1].shape)\n",
    "        layer.set_weights(layer_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not layer_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
